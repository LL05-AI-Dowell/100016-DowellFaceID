{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition as fr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vide_capture = cv2.VideoCapture(0)\n",
    "image = fr.load_image_file(\"image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_face_encoding = fr.face_encodings(image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_encodings = [image_face_encoding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_names = [\"Isaiah\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: List[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n\nInvoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x7fb880d8db70>, array([[[151, 142, 140],\n        [154, 145, 144],\n        [153, 147, 142],\n        ...,\n        [146, 131, 127],\n        [146, 131, 125],\n        [145, 130, 124]],\n\n       [[151, 141, 142],\n        [153, 144, 145],\n        [153, 144, 143],\n        ...,\n        [146, 131, 127],\n        [146, 131, 125],\n        [146, 131, 125]],\n\n       [[151, 141, 142],\n        [151, 141, 142],\n        [149, 143, 140],\n        ...,\n        [146, 131, 127],\n        [146, 131, 127],\n        [147, 132, 128]],\n\n       ...,\n\n       [[102, 104,  96],\n        [102, 104,  96],\n        [105, 106,  99],\n        ...,\n        [ 75,  62,  57],\n        [ 75,  62,  57],\n        [ 75,  62,  57]],\n\n       [[101, 102,  95],\n        [102, 104,  96],\n        [102, 104,  96],\n        ...,\n        [ 76,  63,  58],\n        [ 75,  62,  57],\n        [ 76,  63,  58]],\n\n       [[101, 102,  95],\n        [102, 104,  96],\n        [102, 104,  96],\n        ...,\n        [ 76,  63,  60],\n        [ 76,  63,  60],\n        [ 77,  64,  61]]], dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x7fb880d9b170>, 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/brandon/Desktop/100016-DowellFaceID/image.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/brandon/Desktop/100016-DowellFaceID/image.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m rgb_frame \u001b[39m=\u001b[39m frame[:, :, ::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/brandon/Desktop/100016-DowellFaceID/image.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m fc_locations \u001b[39m=\u001b[39m fr\u001b[39m.\u001b[39mface_locations(rgb_frame)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/brandon/Desktop/100016-DowellFaceID/image.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m fc_encodings \u001b[39m=\u001b[39m fr\u001b[39m.\u001b[39;49mface_encodings(rgb_frame, fc_locations)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/brandon/Desktop/100016-DowellFaceID/image.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m (top, right, bottom, left), fc_encoding \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(fc_locations, fc_encodings):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/brandon/Desktop/100016-DowellFaceID/image.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     matches \u001b[39m=\u001b[39m fr\u001b[39m.\u001b[39mcompare_faces(known_face_encodings, fc_encoding)\n",
      "File \u001b[0;32m~/Desktop/100016-DowellFaceID/myenv/lib/python3.10/site-packages/face_recognition/api.py:214\u001b[0m, in \u001b[0;36mface_encodings\u001b[0;34m(face_image, known_face_locations, num_jitters, model)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39mGiven an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    213\u001b[0m raw_landmarks \u001b[39m=\u001b[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[0;32m--> 214\u001b[0m \u001b[39mreturn\u001b[39;00m [np\u001b[39m.\u001b[39marray(face_encoder\u001b[39m.\u001b[39mcompute_face_descriptor(face_image, raw_landmark_set, num_jitters)) \u001b[39mfor\u001b[39;00m raw_landmark_set \u001b[39min\u001b[39;00m raw_landmarks]\n",
      "File \u001b[0;32m~/Desktop/100016-DowellFaceID/myenv/lib/python3.10/site-packages/face_recognition/api.py:214\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39mGiven an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    213\u001b[0m raw_landmarks \u001b[39m=\u001b[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[0;32m--> 214\u001b[0m \u001b[39mreturn\u001b[39;00m [np\u001b[39m.\u001b[39marray(face_encoder\u001b[39m.\u001b[39;49mcompute_face_descriptor(face_image, raw_landmark_set, num_jitters)) \u001b[39mfor\u001b[39;00m raw_landmark_set \u001b[39min\u001b[39;00m raw_landmarks]\n",
      "\u001b[0;31mTypeError\u001b[0m: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: List[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n\nInvoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x7fb880d8db70>, array([[[151, 142, 140],\n        [154, 145, 144],\n        [153, 147, 142],\n        ...,\n        [146, 131, 127],\n        [146, 131, 125],\n        [145, 130, 124]],\n\n       [[151, 141, 142],\n        [153, 144, 145],\n        [153, 144, 143],\n        ...,\n        [146, 131, 127],\n        [146, 131, 125],\n        [146, 131, 125]],\n\n       [[151, 141, 142],\n        [151, 141, 142],\n        [149, 143, 140],\n        ...,\n        [146, 131, 127],\n        [146, 131, 127],\n        [147, 132, 128]],\n\n       ...,\n\n       [[102, 104,  96],\n        [102, 104,  96],\n        [105, 106,  99],\n        ...,\n        [ 75,  62,  57],\n        [ 75,  62,  57],\n        [ 75,  62,  57]],\n\n       [[101, 102,  95],\n        [102, 104,  96],\n        [102, 104,  96],\n        ...,\n        [ 76,  63,  58],\n        [ 75,  62,  57],\n        [ 76,  63,  58]],\n\n       [[101, 102,  95],\n        [102, 104,  96],\n        [102, 104,  96],\n        ...,\n        [ 76,  63,  60],\n        [ 76,  63,  60],\n        [ 77,  64,  61]]], dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x7fb880d9b170>, 1"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frame = vide_capture.read()\n",
    "    rgb_frame = frame[:, :, ::-1]\n",
    "\n",
    "    fc_locations = fr.face_locations(rgb_frame)\n",
    "    fc_encodings = fr.face_encodings(rgb_frame, fc_locations)\n",
    "\n",
    "    for (top, right, bottom, left), fc_encoding in zip(fc_locations, fc_encodings):\n",
    "        matches = fr.compare_faces(known_face_encodings, fc_encoding)\n",
    "\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        face_distances = fr.face_distance(known_face_encodings, fc_encoding)\n",
    "        match_index = np.argmin(face_distances)\n",
    "        if matches[best_match_index]:\n",
    "            name = known_face_names[match_index]\n",
    "\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
